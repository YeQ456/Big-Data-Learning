{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9319d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e4b268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:13.921249100Z",
     "start_time": "2024-05-11T16:24:13.609264700Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"FinalCoursework\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f061c593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:16.677145600Z",
     "start_time": "2024-05-11T16:24:13.615068400Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_path=\"/mnt/data/project-data/2020tweets\"\n",
    "\n",
    "df_trump = spark.read.option(\"multiline\", True).csv(\"data/hashtag_donaldtrump.csv\", header=True, inferSchema=True)\n",
    "df_biden = spark.read.option(\"multiline\", True).csv(\"data/hashtag_joebiden.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28aab010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:16.708428600Z",
     "start_time": "2024-05-11T16:24:16.680150Z"
    }
   },
   "outputs": [],
   "source": [
    "def transer_data_type(data):\n",
    "  data = data.withColumn(\"likes\", data[\"likes\"].cast(\"int\"))\n",
    "  data = data.withColumn(\"retweet_count\", data[\"retweet_count\"].cast(\"int\"))\n",
    "  data = data.withColumn(\"user_followers_count\", data[\"user_followers_count\"].cast(\"int\"))\n",
    "  data = data.withColumn(\"lat\", data[\"lat\"].cast(\"float\"))\n",
    "  data = data.withColumn(\"long\", data[\"long\"].cast(\"float\"))\n",
    "  return data\n",
    "\n",
    "df_trump = transer_data_type(df_trump)\n",
    "df_biden = transer_data_type(df_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a1c0b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:16.718932900Z",
     "start_time": "2024-05-11T16:24:16.706402200Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dropping columns\n",
    "remove_columns = ['created_at', 'tweet_id', 'user_id', 'user_screen_name', 'user_join_date', 'collected_at', 'user_name', 'user_description', 'user_location', 'lat', 'long', 'city', 'country', 'continent', 'state', 'state_code']\n",
    "df_trump = df_trump.drop(*remove_columns)\n",
    "df_biden = df_biden.drop(*remove_columns)\n",
    "\n",
    "#Dropping rows with na values\n",
    "df_trump = df_trump.na.drop()\n",
    "df_biden = df_biden.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b91858d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:20.894208200Z",
     "start_time": "2024-05-11T16:24:16.719966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgbklEQVR4nO3de7xVVb338c838IIXEBRNgcQSj6HHvBBej5cwwKwwj3boeEGzPPp40k5X9emESqaeLpadNDXveTIj825KGPRYpuBdMI+oJAgqCiqSmuDv+WOOJXNv1157sjdj7/bi+3691mvNOeYcY/7W2muv3xpjzjWWIgIzM7PV7T3dHYCZmTUnJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzy8IJxjpN0uWSvtVNx5akyyQtkXRvd8SQg6RvSXpR0nPdHUtPJGmopJDUu4P1fyLpPxtsD0lbdzzCNYMTTBOSNFfS85LWL5V9TtK0bgwrl72AjwKDI2JkeYOkUyW9lm5vSFpRWp+VMyhJR0m6q4N1hwBfBoZHxHs7Gcf7So/5tfTGuKy0/k+dab+nSv8jr6fnYImkW9LzDkBEHBcRk7ozxmbgBNO8egMndXcQq0pSr1WssiUwNyKWtd4QEd+OiA0iYgPgOODu2npEbLc64s1kS+CliHhhVSu2/sQeEc+UHvMGqfhDpbL/11bdNcAn0nOyOfA88KNujqfpOME0r+8AX5G0UesN9YYPJE2T9Lm0fJSkP0g6V9LLkp6StEcqnyfpBUkTWjW7iaQpkpZKmi5py1Lb26ZtiyU9LunTpW2XS7pA0q2SlgH71Yl3C0k3pvpzJH0+lR8D/BTYPX0SPb3KEyPpdEk/SstrpU/0/5XW+6TeTv+0vpukP6bn4SFJ+5ba6SfpEkkLJT2bhrV6Sfog8JNSXC+n/T8maXZ6jp6V9JU6se0PTAG2SHUvT+WflDQrxTEtHaNWZ66kr0t6GFhWNVG0+jsvBk6TdJqkn5X2afFaScf+VnpOXpN0k6SNJV0t6VVJMyQNLdUPSSem19CLkr4jqe77jqSRku5Oj3GhpP+WtHarto6T9ETqdfxYktK2XpK+m47xFHBglecAICLeACYDw0vHajHsK+mrKaYFkj7bKu510rGfUTFy8BNJfdK2fSXNl/Tl9H+zUNLRVWPr8SLCtya7AXOB/YHrgG+lss8B09LyUCCA3qU604DPpeWjgOXA0UAv4FvAM8CPgXWA0cBSYIO0/+Vpfe+0/YfAXWnb+sC81FZvYGfgRWC7Ut1XgD0pPvCsW+fxTAfOB9YFdgQWAaNKsd5V4Tk5qhTTR4BH0vIewJPAPaVtD6XlQcBLwMdSbB9N6wPT9uuBC9Nj3BS4F/i3tuICFgL/lJb7Azu3Eeu+wPzS+jbAsnT8tYCvAXOAtUt/7weBIUCfdp6HALZu9Xf+Qvrb9AFOA35W2n8opdcKxetkDvABoB8wG/hfitdbb+BK4LJWx/sdMAB4X9r3c23EtguwW2pnKPAY8MVWbd0MbJTaWgSMTduOA/6cnoMB6ZgtXuP1/kfS8nrAFcCVpe2Xs/J/ZyxFD2f79Lf+n1bP4w+AG9NxNwRuAs4q/S2XA2ekv93HgL8C/bv7faIrbu7BNLdvAl+QNLADdZ+OiMsiYgXwC4p/3DMi4s2IuAP4G1A+yXlLRPw+It4E/i/Fp/chwMcphrAui4jlEXE/8CvgkFLdGyLiDxHxdhSfJt+R2tgL+HpEvBERD1L0Wo7owGOquRsYJmljiqR4CTBI0gbAPhQJDeBw4NaIuDXFNgWYCXxM0mbAARRvgMuiGM46Fxjf4LhvAcMl9Y2IJem5qOJfKJ7fKRHxFvBdimSwR2mf8yJiXkS8XrHNmgUR8aP0t6la97KIeDIiXgFuA56MiN9GxHLgl8BOrfY/JyIWR8QzFG/Gn6nXaETcFxF/SrHMpUje+7Ta7eyIeDm19TuKDxwAnwZ+kJ6DxcBZFR7H9al3+SpF8v5OG/t9Oj3mR6MYij2ttiH1oD4P/Ed6jEuBb9PydfAWxf/OWxFxK/Aa8A8V4uvxnGCaWEQ8SvGJ7+QOVH++tPx6aq912Qal9Xml474GLAa2oDifsGsa9ng5/UMfBry3Xt06tgBq/7g1f6HoXXRIeiOdSfHmtTdFQvkjRS+qnGC2BA5tFfteFGP2W1J8Il1Y2nYhRU+mLf9M8Qn2LyqGEXevGPIWFI+5Fv/bFM9Z+Tlo9Bw20pF6rV8HjV4XrY/xF4rH8y6StpF0s6TnJL1K8Ua9SavdylfV/bV0rC3qHKc9B0XERhS97n8Hpkuqd1FFo7YHUvSA7iu9Dn6TymteSsm3XtxNzQmm+U2k+IRVfjOqnRBfr1TWqauVKHo4AKSewABgAcU/5vSI2Kh02yAiji/VbTSl9wJggKQNS2XvA57tZLzTKYbDdgJmpPUxwEjg92mfecBVrWJfPyLOTtveBDYpbesbKy8eeNdjiogZETGOIgldD1xbMdYFFAkNeOdT8xBaPgcdnRa9db1lrN7XBZReGxR/uwVt7HcBxTDXsIjoC5wKqOIxFtY5TiURsSIirgNWUHyAWJW2X6RIqtuVXgf9YuUFFWs0J5gmFxFzKIa4TiyVLaJ4czo8nRz9LMWYemd8TNJe6aTsJIpzGvMoelDbSDpCxQn1tSR9uHySup3451H0Ls6StK6kHYBjgKs7Ge904EhgdkT8jXQOimJocFHa52fAJySNSc/Tuumk7eCIWAjcAXxPUl9J75H0AUm1IZ3ngcG1k9SS1pZ0mKR+aZjrVYo3tCquBQ6UNErSWhSXML9J8bysbg8Ce6u4vLkfcMpqaPOrkvqn4c6TKF6P9WxI8by8Jmlb4Pg29qvnWuBESYNVXKBRudeuwjiK82KPtdH2UZKGS1qP4kMb8E5v8mLgXEmbpvYGSRqzCrE3LSeYNcMZFCcnyz4PfJXipPV2dP7N6n8o/vEWU5ysPQwgDW2NphiTXkAxxHEOxbBEVZ+hOOm7APg1MDGdD+mMP1Kcx6j1VmYDb5TWa8ltHMUn6UUUvZavsvL/5khg7VR3CcWVSJunbXcCs4DnJL2Yyo4A5qbhn+MozvG0KyIeT/v+iOIT8ycoLrH92yo94mrHmkKRAB4G7qP4gNBZN6S2HgRuoTjnVc9XgH+luGDkYtpORPVcDNwOPATcT3GBS3tukvQaRVI7E5gQEe/6flRE3EZx7uhOigsc7my1y9dT+Z/S3/a3rCHnWNqjCP/gmJnlISkohrzmdHcs1vXcgzEzsyycYMzMLAsPkZmZWRbuwZiZWRZr2uR2bdpkk01i6NCh3R2GmVmPct99970YEXVnC3GCSYYOHcrMmTO7Owwzsx5FUpuzJniIzMzMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLLwN/lXk6En39LdIdjfqblnH9jdIZh1C/dgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzyyJrgpH0H5JmSXpU0s8lrStpgKQpkp5I9/1L+58iaY6kxyWNKZXvIumRtO08SUrl60j6RSq/R9LQUp0J6RhPSJqQ83Gamdm7ZUswkgYBJwIjImJ7oBcwHjgZmBoRw4CpaR1Jw9P27YCxwPmSeqXmLgCOBYal29hUfgywJCK2Bs4FzkltDQAmArsCI4GJ5URmZmb55R4i6w30kdQbWA9YAIwDrkjbrwAOSsvjgGsi4s2IeBqYA4yUtDnQNyLujogArmxVp9bWZGBU6t2MAaZExOKIWAJMYWVSMjOzLpAtwUTEs8B3gWeAhcArEXEHsFlELEz7LAQ2TVUGAfNKTcxPZYPScuvyFnUiYjnwCrBxg7ZakHSspJmSZi5atKjjD9bMzN4l5xBZf4oexlbAFsD6kg5vVKVOWTQo72idlQURF0XEiIgYMXDgwAahmZnZqso5RLY/8HRELIqIt4DrgD2A59OwF+n+hbT/fGBIqf5giiG1+Wm5dXmLOmkYrh+wuEFbZmbWRXImmGeA3SStl86LjAIeA24Eald1TQBuSMs3AuPTlWFbUZzMvzcNoy2VtFtq58hWdWptHQLcmc7T3A6MltQ/9aRGpzIzM+sivXM1HBH3SJoM3A8sBx4ALgI2AK6VdAxFEjo07T9L0rXA7LT/CRGxIjV3PHA50Ae4Ld0ALgGukjSHoucyPrW1WNIkYEba74yIWJzrsZqZ2bup+MBvI0aMiJkzZ3a4/tCTb1mN0VgzmXv2gd0dglk2ku6LiBH1tvmb/GZmloUTjJmZZeEEY2ZmWTjBmJlZFk4wZmaWhROMmZll4QRjZmZZZPuipZn9ffF3tawtub6r5R6MmZll4QRjZmZZOMGYmVkWTjBmZpaFE4yZmWXhBGNmZlk4wZiZWRZOMGZmloUTjJmZZeEEY2ZmWTjBmJlZFk4wZmaWhROMmZll4QRjZmZZOMGYmVkWq5RgJPWXtEOuYMzMrHm0m2AkTZPUV9IA4CHgMknfzx+amZn1ZFV6MP0i4lXgYOCyiNgF2D9vWGZm1tNVSTC9JW0OfBq4OXM8ZmbWJKokmNOB24E5ETFD0vuBJ/KGZWZmPV3vCvssjIh3TuxHxFM+B2NmZu2p0oP5UcUyMzOzd7TZg5G0O7AHMFDSl0qb+gK9cgdmZmY9W6MhsrWBDdI+G5bKXwUOyRmUmZn1fG0mmIiYDkyXdHlE/EXS+hGxrAtjMzOzHqzKOZgtJM0GHgOQ9CFJ5+cNy8zMeroqCeYHwBjgJYCIeAjYO2NMZmbWBCrNRRYR81oVrcgQi5mZNZEqCWaepD2AkLS2pK+QhsvaI2kjSZMl/VnSY5J2lzRA0hRJT6T7/qX9T5E0R9LjksaUyneR9Ejadp4kpfJ1JP0ild8jaWipzoR0jCckTaj6hJiZ2epRJcEcB5wADALmAzum9Sp+CPwmIrYFPkSRmE4GpkbEMGBqWkfScGA8sB0wFjhfUu1y6AuAY4Fh6TY2lR8DLImIrYFzgXNSWwOAicCuwEhgYjmRmZlZfu0mmIh4MSIOi4jNImLTiDg8Il5qr56kvhTnai5J7fwtIl4GxgFXpN2uAA5Ky+OAayLizYh4GpgDjEzzoPWNiLsjIoArW9WptTUZGJV6N2OAKRGxOCKWAFNYmZTMzKwLVJmufxtJUyU9mtZ3kPSNCm2/H1hEMb3/A5J+Kml9YLOIWAiQ7jdN+w8Cyud65qeyWs+pdXmLOhGxHHgF2LhBW60f27GSZkqauWjRogoPyczMqqoyRHYxcArwFkBEPEwxlNWe3sDOwAURsROwjDQc1gbVKYsG5R2ts7Ig4qKIGBERIwYOHNggNDMzW1VVEsx6EXFvq7LlFerNB+ZHxD1pfTJFwnk+DXuR7l8o7T+kVH8wsCCVD65T3qKOpN5AP2Bxg7bMzKyLVEkwL0r6AKkHIOkQYGF7lSLiOYor0P4hFY0CZgM3ArWruiYAN6TlG4Hx6cqwrShO5t+bhtGWStotnV85slWdWluHAHem8zS3A6PTTzz3B0anMjMz6yJVpus/AbgI2FbSs8DTwGEV2/8CcLWktYGngKMpktq1ko4BngEOBYiIWZKupUhCy4ETIqL2fZvjgcuBPsBt6QbFBQRXSZpD0XMZn9paLGkSMCPtd0ZELK4Ys5mZrQbtJpiIeArYP52gf09ELK3aeEQ8CIyos2lUG/ufCZxZp3wmsH2d8jdICarOtkuBS6vGamZmq1eVq8ielHQ1cAQtz2uYmZm1qco5mOHAhRSX/35X0lOSfp03LDMz6+mqJJgVFJcorwDeBp5n5ZVfZmZmdVU5yf8q8AjwfeDiKt/iNzMzq9KD+Qzwe+D/ANdIOl1S3ZP0ZmZmNVWuIrsBuEHStsABwBeBr1FcMmxmZlZXmz0YSXek+19JepJiZuT1Kb7o6JmJzcysoUY9mE3S/dnA/aUvPZqZmbWrUYLZSNLBaXlI+o2vd0TEddmiMjOzHq9RgukHfJy2ZyZ2gjEzszY1SjB/iYjPdlkkZmbWVBpdplyv52JmZlZJowRzRJdFYWZmTafNBBMRj3ZlIGZm1lyqfJPfzMxslTX6ouXUdH9O14VjZmbNotFVZJtL2gf4pKRraHXSPyLuzxqZmZn1aI0SzDeBk4HBFDMplwXwkVxBmZlZz9dmgomIycBkSf8ZEZO6MCYzM2sCVWZTniTpk8DeqWhaRNycNywzM+vp2r2KTNJZwEnA7HQ7KZWZmZm1qcovWh4I7BgRbwNIugJ4ADglZ2BmZtazVf0ezEal5X4Z4jAzsyZTpQdzFvCApN9RXKq8N+69mJlZO6qc5P+5pGnAhykSzNcj4rncgZmZWc9WpQdDRCwEbswci5mZNRHPRWZmZlk4wZiZWRYNE4yk90jytP1mZrbKGiaY9N2XhyS9r4viMTOzJlHlJP/mwCxJ9wLLaoUR8clsUZmZWY9XJcGcnj0KMzNrOlW+BzNd0pbAsIj4raT1gF75QzMzs56symSXnwcmAxemokHA9RljMjOzJlDlMuUTgD2BVwEi4glg05xBmZlZz1clwbwZEX+rrUjqTfGLlmZmZm2qkmCmSzoV6CPpo8AvgZuqHkBSL0kPSLo5rQ+QNEXSE+m+f2nfUyTNkfS4pDGl8l0kPZK2nSdJqXwdSb9I5fdIGlqqMyEd4wlJE6rGa2Zmq0eVBHMysAh4BPg34FbgG6twjJOAx1q1NzUihgFT0zqShgPjge2AscD5kmoXE1wAHAsMS7exqfwYYElEbA2cC5yT2hoATAR2BUYCE8uJzMzM8ms3waQvW14BTKK4ZPmKiKg0RCZpMMUPlv20VDwutUe6P6hUfk1EvBkRTwNzgJGSNgf6RsTd6bhXtqpTa2syMCr1bsYAUyJicUQsAaawMimZmVkXqHIV2YHAk8B5wH8DcyQdULH9HwBfA94ulW2WZmeuzdJcu2BgEDCvtN/8VDYoLbcub1EnIpYDrwAbN2jLzMy6SJUhsu8B+0XEvhGxD7AfxXBUQ5I+DrwQEfdVjEV1yqJBeUfrlGM8VtJMSTMXLVpUMUwzM6uiSoJ5ISLmlNafAl6oUG9P4JOS5gLXAB+R9DPg+TTsRbqvtTUfGFKqPxhYkMoH1ylvUSdd3dYPWNygrRYi4qKIGBERIwYOHFjhIZmZWVVtJhhJB0s6mGIeslslHZWuxroJmNFewxFxSkQMjoihFCfv74yIwyl+uKx2VdcE4Ia0fCMwPl0ZthXFyfx70zDaUkm7pfMrR7aqU2vrkHSMAG4HRkvqn07uj05lZmbWRRpNFfOJ0vLzwD5peRHQmSuyzgaulXQM8AxwKEBEzJJ0LTAbWA6cEBErUp3jgcuBPsBt6QZwCXCVpDkUPZfxqa3FkiaxMhGeERGLOxGzmZmtojYTTEQcvboOEhHTgGlp+SVgVBv7nQmcWad8JrB9nfI3SAmqzrZLgUs7GrOZmXVOu5NdpuGqLwBDy/t7un4zM2ukynT911MMRd1Ey8uNzczM2lQlwbwREedlj8TMzJpKlQTzQ0kTgTuAN2uFEXF/tqjMzKzHq5Jg/hE4AvgIK4fIIq2bmZnVVSXBfAp4f3nKfjMzs/ZU+Sb/Q8BGmeMwM7MmU6UHsxnwZ0kzaHkOxpcpm5lZm6okmInZozAzs6bTboKJiOldEYiZmTWXKt/kX8rKqe7XBtYClkVE35yBmZlZz1alB7NheV3SQRQ/Q2xmZtamKleRtRAR1+PvwJiZWTuqDJEdXFp9DzCCOr8OaWZmVlblKrLy78IsB+YC47JEY2ZmTaPKOZjV9rswZma25mgzwUj6ZoN6ERGTMsRjZmZNolEPZlmdsvWBY4CNAScYMzNrU6OfTP5ebVnShsBJwNHANcD32qpnZmYG7ZyDkTQA+BJwGHAFsHNELOmKwMzMrGdrdA7mO8DBwEXAP0bEa10WlZmZ9XiNvmj5ZWAL4BvAAkmvpttSSa92TXhmZtZTNToHs8rf8jczM6txEjEzsyycYMzMLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyyyJRhJQyT9TtJjkmZJOimVD5A0RdIT6b5/qc4pkuZIelzSmFL5LpIeSdvOk6RUvo6kX6TyeyQNLdWZkI7xhKQJuR6nmZnVl7MHsxz4ckR8ENgNOEHScOBkYGpEDAOmpnXStvHAdsBY4HxJvVJbFwDHAsPSbWwqPwZYEhFbA+cC56S2BgATgV2BkcDEciIzM7P8siWYiFgYEfen5aXAY8AgYBzFzy+T7g9Ky+OAayLizYh4GpgDjJS0OdA3Iu6OiACubFWn1tZkYFTq3YwBpkTE4vQTz1NYmZTMzKwLdMk5mDR0tRNwD7BZRCyEIgkBm6bdBgHzStXmp7JBabl1eYs6EbEceAXYuEFbZmbWRbInGEkbAL8CvhgRjX5qWXXKokF5R+uUYztW0kxJMxctWtQgNDMzW1VZE4yktSiSy9URcV0qfj4Ne5HuX0jl84EhpeqDgQWpfHCd8hZ1JPUG+gGLG7TVQkRcFBEjImLEwIEDO/owzcysjpxXkQm4BHgsIr5f2nQjULuqawJwQ6l8fLoybCuKk/n3pmG0pZJ2S20e2apOra1DgDvTeZrbgdGS+qeT+6NTmZmZdZHeGdveEzgCeETSg6nsVOBs4FpJxwDPAIcCRMQsSdcCsymuQDshIlakescDlwN9gNvSDYoEdpWkORQ9l/GprcWSJgEz0n5nRMTiTI/TzMzqyJZgIuIu6p8LARjVRp0zgTPrlM8Etq9T/gYpQdXZdilwadV4zcxs9fI3+c3MLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLAsnGDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7MsnGDMzCwLJxgzM8vCCcbMzLJwgjEzsyycYMzMLIumTjCSxkp6XNIcSSd3dzxmZmuSpk0wknoBPwYOAIYDn5E0vHujMjNbczRtggFGAnMi4qmI+BtwDTCum2MyM1tj9O7uADIaBMwrrc8Hdi3vIOlY4Ni0+pqkx7sotma3CfBidwfx90LndHcEVodfoyWdfI1u2daGZk4wqlMWLVYiLgIu6ppw1hySZkbEiO6Ow6wtfo12jWYeIpsPDCmtDwYWdFMsZmZrnGZOMDOAYZK2krQ2MB64sZtjMjNbYzTtEFlELJf078DtQC/g0oiY1c1hrSk87Gh/7/wa7QKKiPb3MjMzW0XNPERmZmbdyAnGzMyycIKxuiRtLOnBdHtO0rOl9bW7Oz6zGkkr0uvyIUn3S9ojlW8haXIbdaZJ8mXKmTXtSX7rnIh4CdgRQNJpwGsR8d3adkm9I2J590Rn1sLrEbEjgKQxwFnAPhGxADikOwNb0znBWGWSLgcWAzsB90taSinxSHoU+Hja/TfAXcBuwEPAZcDpwKbAYRFxb0pcH6CYdWEI8F8RcXGXPSBrRn2BJQCShgI3R8T2kvpQvAaHA48BfWoVJI2meG2uAzwJHB0Rr0maC1wBfAJYCzg0Iv7cdQ+l5/MQma2qbYD9I+LL7ey3NfBDYAdgW+Bfgb2ArwCnlvbbATgQ2B34pqQtVnvE1uz6pCGyPwM/BSbV2ed44K8RsQNwJrALgKRNgG9QvKZ3BmYCXyrVezGVX0Dx2rVV4ARjq+qXEbGiwn5PR8QjEfE2MAuYGsU18Y8AQ0v73RARr0fEi8DvKCYpNVsVr0fEjhGxLTAWuFJS66mi9gZ+BhARDwMPp/LdKHo1f5D0IDCBlnNrXZfu76Pl69Yq8BCZraplpeXltPyQsm5p+c3S8tul9bdp+bpr/UUsfzHLOiwi7k69koH1NtcpEzAlIj7TRpO11+0K/H65ytyDsc6YC+wMIGlnYKsOtDFO0rqSNgb2pZjix6xDJG1LMXPHS602/R44LO2zPcXQLMCfgD0lbZ22rSdpmy4Kt+k5I1tn/Ao4Mg0tzAD+twNt3AvcArwPmJSu/DFbFX3SaxCKHsmEiFjRapTsAuAySQ8DD1K87oiIRZKOAn4uaZ207zfo2GvZWvFUMdZt6l3+bGbNw0NkZmaWhXswZmaWhXswZmaWhROMmZll4QRjZmZZOMGYrQaS3ivpGklPSpot6dbOfp9C0tA0vxuSRkg6r4395qYvFzZq69RG281ycIIx66Q0LcmvgWkR8YGIGE4x39pmq+sYETEzIk7sRBNOMNblnGDMOm8/4K2I+EmtICIeBB6QNDX9RskjksbBOz2TxyRdLGmWpDvSbL9I2iX9rsndwAm19iTtK+nmtLxxqvOApAspvlxY2+96Sfeldo9NZWezckLIq1PZ4ZLuTWUXSuqV+0myNY8TjFnnbU8xGWJrbwCfSrPx7gd8rzQJ4zDgxxGxHfAy8M+p/DLgxIjYvcHxJgJ3RcROwI0UsyDUfDYidgFGACdK2jgiTmblhJCHSfog8C/Anul3VFaQplExW508VYxZPgK+LWlvikk+B7Fy2Ozp1MuBNFOvpH7ARhExPZVfBRxQp929gYMBIuIWSUtK206U9Km0PIQikbWel2sUxXT1M1K+6wO80KFHaNaAE4xZ582i/i8nHkYxq+8uEfFW+gGr2ozT5dmmV1C8yYvqs0m/az9J+wL7A7tHxF8lTaPlDNfv7ApcERGnVDyWWYd4iMys8+4E1pH0+VqBpA9T/K7ICym57EfL3xl5l4h4GXhF0l6pqK1hq/LMwAcA/VN5P2BJSi7bUvzWSc1bktZKy1OBQyRtmtoYIKlhbGYd4QRj1knph9Q+BXw0XaY8CzgNuBUYIWkmRUKo8nO7RwM/Tif5X29jn9OBvSXdD4wGnknlvwF6pxmDJ1FMRV9zEfCwpKsjYjbFjMF3pH2nAJtXfsBmFXkuMjMzy8I9GDMzy8IJxszMsnCCMTOzLJxgzMwsCycYMzPLwgnGzMyycIIxM7Ms/j/2299qpfhk4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(['Trump', 'Biden'], [df_trump.count(), df_biden.count()])\n",
    "plt.xlabel('Candidate')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Number of Tweets for Trump and Biden')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff130ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:20.903795Z",
     "start_time": "2024-05-11T16:24:20.893208300Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "#Adding a presidents column where 0 represents trump and 1 represents biden. This will turn it into a classification problem\n",
    "df_trump = df_trump.withColumn('President', lit(0))\n",
    "df_biden = df_biden.withColumn('President', lit(1))\n",
    "\n",
    "#Merging the 2 datasets\n",
    "df = df_trump.union(df_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f56edd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:20.966203500Z",
     "start_time": "2024-05-11T16:24:20.904794100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+------------------+--------------------+---------+\n",
      "|               tweet|likes|retweet_count|            source|user_followers_count|President|\n",
      "+--------------------+-----+-------------+------------------+--------------------+---------+\n",
      "|#Elecciones2020 |...|    0|            0|         TweetDeck|                1860|        0|\n",
      "|Usa 2020, Trump c...|   26|            9|  Social Mediaset |             1067661|        0|\n",
      "|#Trump: As a stud...|    2|            1|   Twitter Web App|                1185|        0|\n",
      "|2 hours since las...|    0|            0|     Trumpytweeter|                  32|        0|\n",
      "|You get a tie! An...|    4|            3|Twitter for iPhone|                5393|        0|\n",
      "+--------------------+-----+-------------+------------------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655d594d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:20.979326200Z",
     "start_time": "2024-05-11T16:24:20.966203500Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "#Extracts all the hastags from the tweet and stores them in a list\n",
    "@udf(returnType=ArrayType(StringType()))\n",
    "def getHashtagList(tweet):\n",
    "  tweet = tweet.lower()\n",
    "  tweet = re.sub(r'[^\\w\\s#]', '', tweet)\n",
    "  hashtag_list = []\n",
    "\n",
    "  for word in tweet.split():\n",
    "    if word[0] == '#':\n",
    "      hashtag_list.append(word)\n",
    "  \n",
    "  #Creates a dictionary where the hashtags are the key and their frequency in the list is the value\n",
    "  count_hashtags = Counter(hashtag_list)\n",
    "\n",
    "  #Remove duplicate hashtags\n",
    "  unique_hashtags = [hashtag for hashtag, frequency in count_hashtags.items() if frequency == 1]\n",
    "\n",
    "  return hashtag_list\n",
    "\n",
    "#Creates a column called hashtags which stores a hastag list for all the tweets\n",
    "df = df.withColumn('hashtags', getHashtagList(df['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5896c8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:21.614984Z",
     "start_time": "2024-05-11T16:24:20.980327800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+------------------+--------------------+---------+--------------------+\n",
      "|               tweet|likes|retweet_count|            source|user_followers_count|President|            hashtags|\n",
      "+--------------------+-----+-------------+------------------+--------------------+---------+--------------------+\n",
      "|#Elecciones2020 |...|    0|            0|         TweetDeck|                1860|        0|[#elecciones2020,...|\n",
      "|Usa 2020, Trump c...|   26|            9|  Social Mediaset |             1067661|        0|      [#donaldtrump]|\n",
      "|#Trump: As a stud...|    2|            1|   Twitter Web App|                1185|        0|            [#trump]|\n",
      "|2 hours since las...|    0|            0|     Trumpytweeter|                  32|        0|            [#trump]|\n",
      "|You get a tie! An...|    4|            3|Twitter for iPhone|                5393|        0|     [#trump, #iowa]|\n",
      "+--------------------+-----+-------------+------------------+--------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b46b3f14f6bb94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:21.615988100Z",
     "start_time": "2024-05-11T16:24:21.614984Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78b32cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:21.673831200Z",
     "start_time": "2024-05-11T16:24:21.617987700Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "    \n",
    "#Splits the hashtag list and displays each hashtag in its own row in column hashtag\n",
    "df_exploded = df.withColumn('hashtag', F.explode(df['hashtags']))\n",
    "\n",
    "#Creates a new column called count which displays how many rows the hashtag appears in\n",
    "#The counts will be used in TF-IDF calculation\n",
    "df_count = df_exploded.groupBy(\"hashtag\").count()\n",
    "\n",
    "#Renaming count to hashtag_count\n",
    "df_count = df_count.withColumnRenamed('count', 'hashtag_count')\n",
    "\n",
    "#Joining df_count with df_exploded on hashtag\n",
    "df_exploded = df_exploded.join(df_count, on=\"hashtag\", how=\"left\")\n",
    "\n",
    "# Group by original columns and collect list of counts\n",
    "df = df_exploded.groupBy(df.columns).agg(F.collect_list(\"hashtag_count\").alias(\"hashtag_counts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe0564c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:46.762510200Z",
     "start_time": "2024-05-11T16:24:21.652830100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+\n",
      "|               tweet|likes|retweet_count|             source|user_followers_count|President|            hashtags|      hashtag_counts|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+\n",
      "| He’s nothing mor...|    0|            0|    Twitter Web App|                  71|        0|            [#trump]|            [968674]|\n",
      "| it shows that #t...|    1|            0|Twitter for Android|                  11|        0|            [#trump]|            [968674]|\n",
      "| media-sourced po...|    0|            0|Twitter for Android|                 657|        0|            [#biden]|            [631862]|\n",
      "| mientras hace ca...|    0|            0| Twitter for iPhone|                  14|        1|[#electionday, #d...|[631862, 78352, 6...|\n",
      "| so Please get a ...|    0|            0|Twitter for Android|                 208|        0|             [#mask]|          [682, 682]|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181a3996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:59.171721400Z",
     "start_time": "2024-05-11T16:24:46.762510200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1643761\n"
     ]
    }
   ],
   "source": [
    "#Total number of rows\n",
    "#This value is used to calculate TF-IDF\n",
    "df_count = df.count()\n",
    "print(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "511cd441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:24:59.186494100Z",
     "start_time": "2024-05-11T16:24:59.172722300Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "import math\n",
    "\n",
    "#Creates the TF_IDF list column\n",
    "@udf(returnType=FloatType())\n",
    "def getAvg_TF_IDF(hashtags, hashtag_counts, df_count):\n",
    "  avg_TF_IDF = 0\n",
    "  count = 0\n",
    "\n",
    "  #If there are no hashtags the tweet will be given a value of 0\n",
    "  if len(hashtags) == 0:\n",
    "    return 0.0\n",
    "\n",
    "  for hashtag in hashtags:\n",
    "    #Calculating TF\n",
    "    #Since all the hastags are unique 1 is being divided by the total number of hastags\n",
    "    TF = 1 / len(hashtags)\n",
    "    #nDocs is the number of rows/tweets the hastag is used\n",
    "    nDocs = hashtag_counts[count]\n",
    "    #Calculating IDF\n",
    "    #df_count is the total number of rows/tweets\n",
    "    IDF = math.log(df_count / nDocs)\n",
    "    TF_IDF = TF * IDF\n",
    "    avg_TF_IDF += TF_IDF\n",
    "    count += 1\n",
    "\n",
    "  avg_TF_IDF /= count\n",
    "  return avg_TF_IDF\n",
    "\n",
    "# Apply the UDF to your DataFrame\n",
    "df = df.withColumn('TF_IDF', getAvg_TF_IDF(df['hashtags'], df['hashtag_counts'], lit(df_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e3623ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:25:25.858887900Z",
     "start_time": "2024-05-11T16:24:59.186494100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+\n",
      "|               tweet|likes|retweet_count|             source|user_followers_count|President|            hashtags|      hashtag_counts|   TF_IDF|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+\n",
      "| He’s nothing mor...|    0|            0|    Twitter Web App|                  71|        0|            [#trump]|            [968674]|0.5288141|\n",
      "| it shows that #t...|    1|            0|Twitter for Android|                  11|        0|            [#trump]|            [968674]|0.5288141|\n",
      "| media-sourced po...|    0|            0|Twitter for Android|                 657|        0|            [#biden]|            [631862]|0.9560712|\n",
      "| mientras hace ca...|    0|            0| Twitter for iPhone|                  14|        1|[#electionday, #d...|[631862, 78352, 6...|0.7559104|\n",
      "| so Please get a ...|    0|            0|Twitter for Android|                 208|        0|             [#mask]|          [682, 682]| 7.787468|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b59403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:25:25.873610800Z",
     "start_time": "2024-05-11T16:25:25.859888100Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "import math\n",
    "\n",
    "#Creates the TF_IDF list column\n",
    "@udf(returnType=ArrayType(FloatType()))\n",
    "def getAvg_TF_IDF(hashtags, hashtag_counts, df_count):\n",
    "  TF_IDF_list = []\n",
    "  count = 0\n",
    "\n",
    "  #If there are no hashtags the tweet will be given a value of 0\n",
    "  if len(hashtags) == 0:\n",
    "    return 0.0\n",
    "\n",
    "  for hashtag in hashtags:\n",
    "    #Calculating TF\n",
    "    #Since all the hastags are unique 1 is being divided by the total number of hastags\n",
    "    TF = 1 / len(hashtags)\n",
    "    #nDocs is the number of rows/tweets the hastag is used\n",
    "    nDocs = hashtag_counts[count]\n",
    "    #Calculating IDF\n",
    "    #df_count is the total number of rows/tweets\n",
    "    IDF = math.log(df_count / nDocs)\n",
    "    TF_IDF = TF * IDF\n",
    "    TF_IDF_list.append(TF_IDF)\n",
    "    count += 1\n",
    "\n",
    "  return TF_IDF_list\n",
    "\n",
    "# Apply the UDF to your DataFrame\n",
    "df = df.withColumn('TF_IDF_list', getAvg_TF_IDF(df['hashtags'], df['hashtag_counts'], lit(df_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d037cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:25:53.058230Z",
     "start_time": "2024-05-11T16:25:25.874610200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+\n",
      "|               tweet|likes|retweet_count|             source|user_followers_count|President|            hashtags|      hashtag_counts|   TF_IDF|         TF_IDF_list|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+\n",
      "| He’s nothing mor...|    0|            0|    Twitter Web App|                  71|        0|            [#trump]|            [968674]|0.5288141|         [0.5288141]|\n",
      "| it shows that #t...|    1|            0|Twitter for Android|                  11|        0|            [#trump]|            [968674]|0.5288141|         [0.5288141]|\n",
      "| media-sourced po...|    0|            0|Twitter for Android|                 657|        0|            [#biden]|            [631862]|0.9560712|         [0.9560712]|\n",
      "| mientras hace ca...|    0|            0| Twitter for iPhone|                  14|        1|[#electionday, #d...|[631862, 78352, 6...|0.7559104|[0.1593452, 0.507...|\n",
      "| so Please get a ...|    0|            0|Twitter for Android|                 208|        0|             [#mask]|          [682, 682]| 7.787468|          [7.787468]|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0a2133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:25:53.061772500Z",
     "start_time": "2024-05-11T16:25:53.059229800Z"
    }
   },
   "outputs": [],
   "source": [
    "import re,string\n",
    "# This code defines a function named \"tokenize\" that tokenizes the input text.\n",
    "# It removes special characters, converts the text to lowercase, and removes stopwords and punctuation.\n",
    "# The resulting tokens are added to a list and returned.\n",
    "\n",
    "# This code defines a list of stopwords to be removed from the text.\n",
    "stopwords = [u'rt', u're', u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your',\n",
    "             u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers',\n",
    "             u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what',\n",
    "             u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were',\n",
    "             u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a',\n",
    "             u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by',\n",
    "             u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after',\n",
    "             u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under',\n",
    "             u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all',\n",
    "             u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not',\n",
    "             u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don',\n",
    "             u'should', u'now']\n",
    "def tokenize(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Split text into tokens and filter out stopwords, single characters, and '``'\n",
    "    tokens = [word for word in text.split() if word not in stopwords and len(word) > 1 and word != '``']\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e6d4c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:25:53.130149400Z",
     "start_time": "2024-05-11T16:25:53.066773Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sc.broadcast(sia)\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    #sia = SentimentIntensityAnalyzer()\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "    sentiment_scores = sia.polarity_scores(text)['compound']\n",
    "\n",
    "    return sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d34651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:25:53.155144100Z",
     "start_time": "2024-05-11T16:25:53.088375500Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Define UDF to tokenize the tweet attribute\n",
    "@udf(returnType=FloatType())\n",
    "def polarize_tweet(text):\n",
    "    # Write code here to tokenize the tweet using the desired method/function\n",
    "    tokens = tokenize(text)\n",
    "    sent=calculate_sentiment(tokens)\n",
    "    return sent\n",
    "\n",
    "# Add a new column 'Tokens' to the DataFrame 'df' by calling the 'tokenize_tweet' UDF on the 'tweet' column\n",
    "df=df.withColumn('polarity', polarize_tweet(df['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be272240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:26:21.263554100Z",
     "start_time": "2024-05-11T16:25:53.119132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+--------+\n",
      "|               tweet|likes|retweet_count|             source|user_followers_count|President|            hashtags|      hashtag_counts|   TF_IDF|         TF_IDF_list|polarity|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+--------+\n",
      "| He’s nothing mor...|    0|            0|    Twitter Web App|                  71|        0|            [#trump]|            [968674]|0.5288141|         [0.5288141]|  0.0772|\n",
      "| it shows that #t...|    1|            0|Twitter for Android|                  11|        0|            [#trump]|            [968674]|0.5288141|         [0.5288141]|  -0.128|\n",
      "| media-sourced po...|    0|            0|Twitter for Android|                 657|        0|            [#biden]|            [631862]|0.9560712|         [0.9560712]|  0.7579|\n",
      "| mientras hace ca...|    0|            0| Twitter for iPhone|                  14|        1|[#electionday, #d...|[631862, 78352, 6...|0.7559104|[0.1593452, 0.507...|     0.0|\n",
      "| so Please get a ...|    0|            0|Twitter for Android|                 208|        0|             [#mask]|          [682, 682]| 7.787468|          [7.787468]|  0.5994|\n",
      "+--------------------+-----+-------------+-------------------+--------------------+---------+--------------------+--------------------+---------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dbbd4fd78b94523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:26:21.276157200Z",
     "start_time": "2024-05-11T16:26:21.263554100Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df.select('likes', 'retweet_count', 'user_followers_count','polarity','TF_IDF','President')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66103c7e5d3f0a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:28:01.876919600Z",
     "start_time": "2024-05-11T16:26:21.276157200Z"
    }
   },
   "outputs": [],
   "source": [
    "#normalization\n",
    "#from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "\n",
    "# Assemble features into a vector\n",
    "#standardVA = VectorAssembler(inputCols=[\"likes\", \"retweet_count\", \"user_followers_count\",'polarity','TF_IDF'], outputCol=\"features\")\n",
    "#df = standardVA.transform(df)\n",
    "\n",
    "\n",
    "# Initialize and fit the StandardScaler\n",
    "#scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=False)\n",
    "#scalerModel = scaler.fit(df)\n",
    "#df=scalerModel.transform(df)\n",
    "\n",
    "#df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe4ec264f7f4249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:33:26.846963700Z",
     "start_time": "2024-05-11T16:28:01.875919500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Started\n",
      "Sampling centroids\n",
      "Broadcast current centroids\n",
      "Assigning each point to the closest centroid\n",
      "Compute new centroids\n",
      "Calculating difference\n",
      "diff:\n",
      "0.9077786250878408\n",
      "Assigning Noise Points\n",
      "Removing Noise Points\n",
      "Execution Complete\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "\n",
    "def dist(a, b):\n",
    "  return np.sqrt(np.sum((a - b)**2))\n",
    "\n",
    "def getCentroidDistances(point, centroids):\n",
    "    distances = []\n",
    "    \n",
    "    for centroid in centroids:\n",
    "        distances.append(dist(centroid, point))\n",
    "        \n",
    "    return distances\n",
    "\n",
    "def modified_kmeans(df, k, threshold, minDistance, SEED = 1):\n",
    "    #1. Get initial centroids\n",
    "    print(\"Execution Started\")\n",
    "    sample_fraction = k / df_count\n",
    "    print(\"Sampling centroids\")\n",
    "    centroids = df.select('TF_IDF').sample(fraction = sample_fraction, seed = SEED).limit(k).collect()\n",
    "\n",
    "    converged = False\n",
    "\n",
    "    while not converged:\n",
    "        #2. Broadcast current centroids\n",
    "        print(\"Broadcast current centroids\")\n",
    "        centroids_bc = sc.broadcast(np.array(centroids).squeeze())\n",
    "    \n",
    "        print(\"Assigning each point to the closest centroid\")\n",
    "        #3. Assign each data point to closest centroid\n",
    "        @udf(IntegerType())\n",
    "        def getClosestCentroid(value):\n",
    "            distances = []\n",
    "            centroids = centroids_bc.value\n",
    "\n",
    "            for centroid in centroids:\n",
    "                distances.append(dist(centroid, value))\n",
    "\n",
    "            return int(np.argmin(distances))\n",
    "\n",
    "        df = df.withColumn('closest', getClosestCentroid(df['TF_IDF']))\n",
    "        \n",
    "        df.persist()\n",
    "    \n",
    "        print(\"Compute new centroids\")\n",
    "        #4. Compute new centroids and bring back to driver\n",
    "        new_centroids_df = df.groupBy('closest') \\\n",
    "            .agg(F.avg('TF_IDF').alias('TF_IDF')) \\\n",
    "            .orderBy('closest')\n",
    "        \n",
    "        new_centroids = np.array(new_centroids_df.select('TF_IDF').collect()).squeeze()\n",
    "        \n",
    "        count = 0\n",
    "        diff = 0\n",
    "        cent_bc = centroids_bc.value\n",
    "        \n",
    "        print(\"Calculating difference\")\n",
    "        for c in new_centroids:\n",
    "            diff += dist(c, cent_bc[count])\n",
    "            count += 1\n",
    "        \n",
    "        print(\"diff:\")\n",
    "        print(diff)\n",
    "        \n",
    "        if diff < threshold:\n",
    "            converged = True\n",
    "        else:\n",
    "            centroids_bc.unpersist()\n",
    "            centroids = new_centroids\n",
    "        \n",
    "        df.unpersist()\n",
    "    \n",
    "    print(\"Assigning Noise Points\")\n",
    "    \n",
    "    @udf(IntegerType())\n",
    "    def isNoisePoint(value):\n",
    "        centroids = centroids_bc.value\n",
    "        distances = getCentroidDistances(value, centroids)\n",
    "        closestCentroid = int(np.argmin(distances))\n",
    "        \n",
    "        if distances[closestCentroid] < minDistance:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    df = df.withColumn('is_noise_point', isNoisePoint(df['TF_IDF']))\n",
    "    \n",
    "    print(\"Removing Noise Points\")\n",
    "    df = df.filter(df['is_noise_point'] == 0)\n",
    "    \n",
    "    centroids_bc.unpersist()\n",
    "    \n",
    "    print(\"Execution Complete\")\n",
    "    return centroids, df\n",
    "\n",
    "k = 10\n",
    "threshold = 1\n",
    "minDistance = 5\n",
    "centroids, df = modified_kmeans(df, k, threshold, minDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b56ead8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+--------+---------+---------+-------+--------------+\n",
      "|likes|retweet_count|user_followers_count|polarity|   TF_IDF|President|closest|is_noise_point|\n",
      "+-----+-------------+--------------------+--------+---------+---------+-------+--------------+\n",
      "|    0|            0|                  71|  0.0772|0.5288141|        0|      6|             0|\n",
      "|    1|            0|                  11|  -0.128|0.5288141|        0|      6|             0|\n",
      "|    0|            0|                 657|  0.7579|0.9560712|        0|      3|             0|\n",
      "|    0|            0|                  14|     0.0|0.7559104|        1|      3|             0|\n",
      "|  117|           61|               14304|     0.0| 2.734459|        0|      4|             0|\n",
      "+-----+-------------+--------------------+--------+---------+---------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cbdab1487319914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:34:02.012513600Z",
     "start_time": "2024-05-11T16:33:26.846963700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes', 'retweet_count', 'user_followers_count', 'polarity', 'TF_IDF', 'closest']\n",
      "+-----+-------------+--------------------+--------+---------+---------+-------+--------------+--------------------+\n",
      "|likes|retweet_count|user_followers_count|polarity|   TF_IDF|President|closest|is_noise_point|   features_clusters|\n",
      "+-----+-------------+--------------------+--------+---------+---------+-------+--------------+--------------------+\n",
      "|    0|            0|                  71|  0.0772|0.5288141|        0|      6|             0|[0.0,0.0,71.0,0.0...|\n",
      "|    1|            0|                  11|  -0.128|0.5288141|        0|      6|             0|[1.0,0.0,11.0,-0....|\n",
      "|    0|            0|                 657|  0.7579|0.9560712|        0|      3|             0|[0.0,0.0,657.0,0....|\n",
      "|    0|            0|                  14|     0.0|0.7559104|        1|      3|             0|[0.0,0.0,14.0,0.0...|\n",
      "|  117|           61|               14304|     0.0| 2.734459|        0|      4|             0|[117.0,61.0,14304...|\n",
      "+-----+-------------+--------------------+--------+---------+---------+-------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "#feature_columns_xgb = ['scaled_features']\n",
    "feature_columns_xgb=['likes', 'retweet_count', 'user_followers_count','polarity','TF_IDF', 'closest']\n",
    "#feature_columns_xgb = ['scaled_features','kmeans']\n",
    "#feature_columns_xgb = ['kmeans']\n",
    "#feature_columns=df.columns\n",
    "print(feature_columns_xgb)\n",
    "assemblerXGB = VectorAssembler(inputCols=feature_columns_xgb, outputCol=\"features_clusters\")\n",
    "df = assemblerXGB.transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44d6aa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:34:02.077362800Z",
     "start_time": "2024-05-11T16:34:02.012513600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[likes: int, retweet_count: int, user_followers_count: int, polarity: float, TF_IDF: float, President: int, closest: int, is_noise_point: int, features_clusters: vector]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 654321\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3], seed=seed)\n",
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4a54df28bbb10c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T17:06:19.134396200Z",
     "start_time": "2024-05-11T17:06:12.847214400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 04:21:11,609 WARNING SparkXGBClassifier: _validate_gpu_params You have enabled GPU in spark local mode. Please make sure your local node has at least 1 GPUs\n",
      "2024-05-12 04:30:15,099 INFO XGBoost-PySpark: _fit Running xgboost-2.0.1 on 1 workers with\n",
      "\tbooster params: {'objective': 'binary:logistic', 'device': 'cuda', 'learning_rate': 0.15, 'numRound': 100, 'maxDepth': 7, 'alpha': 0.0, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': 0.0}\n",
      "2024-05-12 04:30:16,841 INFO SparkXGBClassifier: _skip_stage_level_scheduling Stage-level scheduling in xgboost requires spark standalone or local-cluster mode\n",
      "2024-05-12 04:30:27,960 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb = SparkXGBClassifier(\n",
    "    enable_sparse_data_optim=True,\n",
    "    missing=0.0,\n",
    "    features_col='features_clusters',\n",
    "    label_col=\"President\",\n",
    "    prediction_col=\"prediction\",\n",
    "    numRound=100,\n",
    "    learning_rate=0.15,\n",
    "    maxDepth=7,\n",
    "    alpha=0.0,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Set up the pipeline\n",
    "pipeline = Pipeline(stages=[xgb])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60bb7c3ce09b12a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T17:06:41.878923500Z",
     "start_time": "2024-05-11T17:06:25.281297500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6660312363455305\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"President\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc475f0ff4120eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:42:37.714268800Z",
     "start_time": "2024-05-11T16:42:37.694721900Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb.max_depth, [3, 5, 7]) \\\n",
    "    .addGrid(xgb.learning_rate, [0.15, 0.01, 0.001]) \\\n",
    "    .build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132190cc1f33f8fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:42:58.637563500Z",
     "start_time": "2024-05-11T16:42:58.613900400Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"President\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7255d8c910d73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T16:43:00.242282200Z",
     "start_time": "2024-05-11T16:43:00.210293200Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=xgb,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca29187de36e29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T17:03:35.787103800Z",
     "start_time": "2024-05-11T16:43:15.091576Z"
    }
   },
   "outputs": [],
   "source": [
    "cvModel = cv.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d690c75158cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T17:05:28.806325600Z",
     "start_time": "2024-05-11T17:05:28.790758800Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cvModel.bestModel.getOrDefault('learning_rate'),cvModel.bestModel.getOrDefault('max_depth'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
