{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a39d36b0e98a5a2b0bb7db44fbf0ba3d",
     "grade": false,
     "grade_id": "cell-34556ecbf3be9299",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Spark RDD\n",
    "## Lab assignment: Exercises with MapReduce on Apache Spark\n",
    "\n",
    "The aim of this notebook is to play with the RDD API of Apache Spark, aiming to solve the same four MapReduce exercises we did for the first lab. \n",
    "\n",
    "Note that in the previous lab, we solved the exercises at a conceptual level, tackling most exercises with **a single Map followed by a single Reduce function**. In Spark, we may be able to concatenate multiple `map` (or `flatMap`) functions to transform the input data into what we want, letting Spark optimize the whole job, which is going to be easier (and more efficient) to implement. Moreover, we will have a lot more functions available apart from Map and Reduce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0940e388760ccf5e1c087185b666a04",
     "grade": false,
     "grade_id": "cell-41d8f418a3488649",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Submission and marking criteria\n",
    "\n",
    "You should complete this notebook and add your solutions to it. When you are done, rename your completed notebook as `ex02.ipynb`. \n",
    "\n",
    "Important notes:\n",
    "- The **group leader** must submit the `ex02.ipynb` file on Moodle.\n",
    "- **Each member of the group** must complete the peer review survey and their contribution statement using this [link](https://forms.office.com/Pages/ResponsePage.aspx?id=7qe9Z4D970GskTWEGCkKHjZupmfSK6JKqlvGZrucaoBUNlJETExBQU1EN1pST0ZQS0xEN1gyTjYyMSQlQCN0PWcu). **You can only submit this survey ONCE**.\n",
    "- This lab is marked out of 100 marks, and each exercise is worth 25 marks.\n",
    "- The marking will be focused on:\n",
    "    - Code that does solve the task correctly (10 marks).\n",
    "    - Efficiency of the solution (15 marks).\n",
    "    - Minor mistakes will deduct marks from each exercise.\n",
    "- **Submission deadline: 4th March 2022 at 3pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56d1dc68ea55559695c6609107f5061a",
     "grade": false,
     "grade_id": "cell-1525f00aaf6b41a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9cfb2fac2b6f9e548fb96bf41ddd5b54",
     "grade": false,
     "grade_id": "cell-f996e77963026a8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The first thing we need to do to start working with Spark is to initialize the `SparkContext`. We will also import a few libraries we will use. *Remember if you are using Databricks that `spark` and `sc` are already available to you and don't need initializing.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark\n",
    "#!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"RDD Lab\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to test the correctness of the solutions\n",
    "def test(var, val, msg=\"\"):\n",
    "    print(\"1 test passed.\") if var == val else print(\"1 test failed. \" + msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c9abac50c3c0a52dd3db1a33383dbc4",
     "grade": false,
     "grade_id": "cell-zzz8f418a3488649",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Useful tips for programming exercises\n",
    "\n",
    "When programming in Spark with Jupyter Notebooks it is useful to make use of its interactivity. That is, instead of addressing the exercise as a whole, try to divide it into smaller pieces and program it incrementally, checking that every step is being performed as expected. \n",
    "\n",
    "To illustrate this, we are going to implement the Word Count program step by step, and you will later be asked to put everything together as part of Exercise 0. \n",
    "\n",
    "We already know that to count words we need to first divide each sentence (string) of the RDD into words. But before that, we should read the data from a file. We can implement a simple function that takes the filename (and its path) as input, and creates an RDD with it. To check that this works, we could use a `take` action right after loading the file and see the first 10 lines of the file. Let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'The Project Gutenberg EBook of The History of Don Quixote by Miguel de Cervantes',\n",
       " '',\n",
       " 'This eBook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  You may copy it, give it away or',\n",
       " 're-use it under the terms of the Project Gutenberg License included',\n",
       " 'with this eBook or online at www.gutenberg.org',\n",
       " '',\n",
       " '',\n",
       " 'Title: The History of Don Quixote']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First step, check the reading\n",
    "def word_count(file_path):\n",
    "    lines = sc.textFile(file_path, 10)\n",
    "    \n",
    "    output = lines.take(10) #Â trigger the reading of the file \n",
    "    return output\n",
    "    \n",
    "# Test the function with quixote.txt file\n",
    "word_count(\"data/quixote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "685704f0344b5235862bfd738a48c9ab",
     "grade": false,
     "grade_id": "cell-0ae9fe835f50a10c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Doing this allows us to see the first 10 elements from the RDD, so we can understand that each element is a string containing a line of the book.\n",
    "\n",
    "The next step is to divide those lines into words using the `split` function for Strings from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[''],\n",
       " ['The',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'EBook',\n",
       "  'of',\n",
       "  'The',\n",
       "  'History',\n",
       "  'of',\n",
       "  'Don',\n",
       "  'Quixote',\n",
       "  'by',\n",
       "  'Miguel',\n",
       "  'de',\n",
       "  'Cervantes'],\n",
       " [''],\n",
       " ['This',\n",
       "  'eBook',\n",
       "  'is',\n",
       "  'for',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'at',\n",
       "  'no',\n",
       "  'cost',\n",
       "  'and',\n",
       "  'with'],\n",
       " ['almost',\n",
       "  'no',\n",
       "  'restrictions',\n",
       "  'whatsoever.',\n",
       "  '',\n",
       "  'You',\n",
       "  'may',\n",
       "  'copy',\n",
       "  'it,',\n",
       "  'give',\n",
       "  'it',\n",
       "  'away',\n",
       "  'or'],\n",
       " ['re-use',\n",
       "  'it',\n",
       "  'under',\n",
       "  'the',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'License',\n",
       "  'included'],\n",
       " ['with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org'],\n",
       " [''],\n",
       " [''],\n",
       " ['Title:', 'The', 'History', 'of', 'Don', 'Quixote']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we check the split\n",
    "def word_count(file_path):\n",
    "    lines = sc.textFile(file_path, 10)\n",
    "    words = lines.map(lambda line: line.split(' '))\n",
    "    output = words.take(10)\n",
    "    return output\n",
    "    \n",
    "# Test the function with quixote.txt file\n",
    "word_count(\"data/quixote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36381e5bbe0583381f773d88ce950df3",
     "grade": false,
     "grade_id": "cell-502zzzeb035b95bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Well, in this case, we get a new RDD composed of lists. Is this what we need? Not really, we want an RDD of words. So looking at that output we can see that we should change something. You may recall that `split` returns a list of words that is split by the character given as argument. Hence, if we just want the words in the RDD we must use `flatMap` instead of `map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'History',\n",
       " 'of',\n",
       " 'Don']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we check the split\n",
    "def word_count(file_path):\n",
    "    lines = sc.textFile(file_path)\n",
    "    words = lines.flatMap(lambda line: line.split(' '))\n",
    "    \n",
    "    output = words.take(10)\n",
    "    return output\n",
    "    \n",
    "# Test the function with quixote.txt file\n",
    "word_count(\"data/quixote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5facafafc2fc7cb3f2d62193619a1de6",
     "grade": false,
     "grade_id": "cell-db7d3fzzz86352",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Brilliant! Much better now. What is left to finish this? We will ask you to think about it in the next section.\n",
    "\n",
    "In summary, all exercises can usually be implemented incrementally, which eases finding bugs and problems. If we tried to program the whole Word Count and tested it at the end, we might get an error and could spend much more time trying to correct it and looking to understand where the error comes from. We suggest you test each step of the way to ensure that you are getting what you expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b41a7223a6b9e713853366b41c439c94",
     "grade": false,
     "grade_id": "cell-8cdb21azzzf3d35e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 0: Word Count with Spark\n",
    "\n",
    "Let's now implement the complete Word Count program in Spark, considering a few additional things we may need when working with real data. Thus, you're asked to implement a `word_count(file_path)` function that counts the number of words in a document or a number of text documents provided in the input path. The function `word_count(file_path)` should give as an output the 10 most repeated words in descending order of repetitions.\n",
    "\n",
    "**Input:** The path to a text file\n",
    "\n",
    "**Output:** (word, count) - only the 10 words with the highest frequency!\n",
    "\n",
    "Recommended steps:\n",
    "1. Read the file or files. Each line should be an element of the RDD. (*transformation*)\n",
    "2. Split the lines into words. (*transformation*)\n",
    "3. Filter empty words (`''`) resulting from previous steps. (*transformation*)\n",
    "4. Count the number of occurrences of each word. (*transformation*)\n",
    "5. Return to the driver program the 10 most repeated words. (*action*)\n",
    "\n",
    "                                                                                                       [0 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcfd60a458abf57df4850989c8015038",
     "grade": false,
     "grade_id": "cell-5b42f769d37azzz2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 20923),\n",
       " ('and', 16606),\n",
       " ('to', 13492),\n",
       " ('of', 12866),\n",
       " ('that', 7164),\n",
       " ('a', 7003),\n",
       " ('in', 6860),\n",
       " ('I', 5756),\n",
       " ('he', 5640),\n",
       " ('for', 4534)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(file_path):\n",
    "    # <FILL-IN WITH YOUR CODE>\n",
    "    lines = sc.textFile(file_path, 10)\n",
    "    words = lines.flatMap(lambda line: line.split(' '))\n",
    "    removeBlanks = words.filter(lambda x: x != '')\n",
    "    mapWords = removeBlanks.map(lambda word: (word, 1))\n",
    "    countWords = mapWords.reduceByKey(lambda x, y: x + y)\n",
    "    orderCounts = countWords.takeOrdered(10, lambda x: -x[1])\n",
    "    return orderCounts\n",
    "    \n",
    "# Test the function with quixote.txt file\n",
    "word_count(\"data/quixote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c54636a09e3371a5eb56f43e50bd55f5",
     "grade": false,
     "grade_id": "cell-8c19ebc1352dbf17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The program should pass the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed47f49915b742fb5b4322a172e5f554",
     "grade": true,
     "grade_id": "cell-ef044zzz0a494e9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 20923), ('and', 16606), ('to', 13492), ('of', 12866), ('that', 7164), ('a', 7003), ('in', 6860), ('I', 5756), ('he', 5640), ('for', 4534)]\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "top10_quixote = word_count(\"data/quixote.txt\")\n",
    "print(top10_quixote)\n",
    "test(top10_quixote, [('the', 20923), ('and', 16606), ('to', 13492), ('of', 12866), \n",
    "                                  ('that', 7164), ('a', 7003), ('in', 6860), ('I', 5756), ('he', 5640), \n",
    "                                  ('for', 4534)], \"Try again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a20f918c3c74bc9247a6a3019178cd47",
     "grade": false,
     "grade_id": "cell-11511dda4bdazzz2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1. Histogram of word repetition\n",
    "\n",
    "Provide a histogram of word repetitions, that is, the number of words that are repeated X times:\n",
    "\n",
    "* 1 time - 3 words\n",
    "* 2 times - 10 words\n",
    "* 3 times, 20 words\n",
    "...\n",
    "\n",
    "You are asked to implement a `histogram_reps(file_path)` function in Spark that **must not** use the function `word_count(file_path)`, but it could use part of the code you did before. All the processing must be done with RDDs, and there should be a single `collect()` at the end to return a list. The list must be ordered by the number of times. \n",
    "\n",
    "**Input**: The path to a text file\n",
    "\n",
    "**Output**: (X times, number of words)\n",
    "\n",
    "                                                                                                       [25 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "540671cc612e521f4dcc0d75ae00eca3",
     "grade": false,
     "grade_id": "cell-f6f39xxx672c31b0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 17817),\n",
       " (2, 5146),\n",
       " (3, 2291),\n",
       " (4, 1520),\n",
       " (5, 998),\n",
       " (6, 737),\n",
       " (7, 589),\n",
       " (8, 439),\n",
       " (9, 333),\n",
       " (10, 288),\n",
       " (11, 227),\n",
       " (12, 216),\n",
       " (13, 184),\n",
       " (14, 199),\n",
       " (15, 143),\n",
       " (16, 128),\n",
       " (17, 109),\n",
       " (18, 97),\n",
       " (19, 91),\n",
       " (20, 90)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def histogram_reps(file_path):\n",
    "    # <FILL-IN WITH YOUR CODE>\n",
    "    lines = sc.textFile(file_path, 10)\n",
    "    words = lines.flatMap(lambda line: line.split(' '))\n",
    "    removeBlanks = words.filter(lambda x: x != '')\n",
    "    mapWords = removeBlanks.map(lambda word: (word, 1))\n",
    "    countWords = mapWords.reduceByKey(lambda x, y: x + y)\n",
    "    mapCounts = countWords.map(lambda x: (x[1], 1))\n",
    "    countWordCounts = mapCounts.reduceByKey(lambda x, y: x + y)\n",
    "    sortByWordCounts = countWordCounts.sortBy(lambda x: x[0], ascending = True)\n",
    "    return sortByWordCounts.collect()\n",
    "    \n",
    "histogram_reps('data/quixote.txt')[:20] # look at the first 20 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7dcbb4eb13423d01a3234881c8ebe91",
     "grade": false,
     "grade_id": "cell-fxxxxx5ac45bd7b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The program should pass the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c465622cfaeffc27210e788a9a43dbbd",
     "grade": true,
     "grade_id": "cell-72qqqqfcbcf69d29",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "hist_quixote = histogram_reps(\"data/quixote.txt\")\n",
    "test(hist_quixote[:10],[(1, 17817), (2, 5146), (3, 2291), (4, 1520), \n",
    "                                     (5, 998), (6, 737), (7, 589), (8, 439), (9, 333), (10, 288)], \"Try again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea5d53971e69c74f788ee2601ef6d353",
     "grade": false,
     "grade_id": "cell-fd97145f212433e6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You could plot this with the matplotlib library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_values, y_values) = zip(*hist_quixote[:10])\n",
    "plt.bar(x_values, y_values)\n",
    "plt.title('Histogram of repetitions (up to 10)')\n",
    "plt.xlabel('Number of repetitions')\n",
    "plt.ylabel('Number of words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86f08afa859e036f86720396b569bd13",
     "grade": false,
     "grade_id": "cell-fbf53529a525252e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2. Histogram of the length of the words\n",
    "\n",
    "Provide a histogram of the length of the words. Word repetition is not a problem, so if you have the word 'bye' twice in your document, you would add 2 to the number of words of length 3.\n",
    "\n",
    "* Length 1 - 100 times\n",
    "* Length 2 - 300 times\n",
    "* Length 3 - 400 times\n",
    "...\n",
    "\n",
    "You are asked to implement a `histogram_length(file_path)` function in Spark. All the processing must be done with RDDs, and there should be a single `collect()` at the end to return a list. The list must be ordered by the length of the words.\n",
    "\n",
    "**Input**: The path to a text file\n",
    "\n",
    "**Output**: (Length, number of words)\n",
    "\n",
    "**Note: We are going to assume that the maximum word length is 16 characters, so anything above that shouldn't appear in the result.**\n",
    "\n",
    "                                                                                                       [25 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc3c3326fa3b4f7895dc678245239fe1",
     "grade": false,
     "grade_id": "cell-c8afo46146af50c4b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def histogram_length(file_path):\n",
    "    # <FILL-IN WITH YOUR CODE>\n",
    "\n",
    "histogram_length(\"data/quixote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e8cb382de01c41ab939331fe567a045",
     "grade": false,
     "grade_id": "cell-74d9340329b15db9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The program should pass the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ce233576c70e918d772750b8de1677",
     "grade": true,
     "grade_id": "cell-733bbe2050000f87",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "length_quixote = histogram_length(\"data/quixote.txt\")\n",
    "print(length_quixote)\n",
    "test(length_quixote, [(1, 12978), (2, 80003), (3, 98414), (4, 80717), (5, 45809), \n",
    "                                   (6, 33672), (7, 30995), (8, 19570), (9, 12350), (10, 7929),\n",
    "                                   (11, 3849), (12, 2043), (13, 963), (14, 539), (15, 251), (16, 110)],\"Try again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7a17862e258fefd1c06f7070792961a",
     "grade": false,
     "grade_id": "cell-8bb0158c3410eb08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task: Draw the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c184121169ad199227d893c86dc526e2",
     "grade": false,
     "grade_id": "cell-zws6fa570692b4fc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# <FILL-IN WITH YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b02c67d8e37f501ab9a3a3818e92597",
     "grade": false,
     "grade_id": "cell-7c0a25f4d71b15a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3. Average length of the words in a document\n",
    "\n",
    "You are now asked to implement an `average_length(file_path)` function in Spark that provides the average length of the words in a document or documents. All the processing must be done with RDDs, and the last instruction must be the only one returning a result to the driver. \n",
    "\n",
    "**Input**: The path to a text file\n",
    "\n",
    "**Output**: Average length of the words\n",
    "\n",
    "**Note: Again, we are going to assume that the maximum word length is 16 characters, so anything above that shouldn't be used to compute the average**\n",
    "\n",
    "You can do it in two different ways (you can try both and check possible differences): \n",
    "\n",
    "- **Option 1**. As we have done in the previous lab: you will need to get the total length of the words in the text and the total number of words in just one MapReduce job. Then, you just need to make the division.\n",
    "\n",
    "\n",
    "                                                                                                       [15 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d41bbe12130a270bf5a4aa0583e980dd",
     "grade": false,
     "grade_id": "cell-c599988574d599e2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def average_length(file_path):\n",
    "    # <FILL-IN WITH YOUR CODE>\n",
    "    \n",
    "average_length(\"data/quixote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15121fcdfebe057f1325e22c484a71d5",
     "grade": false,
     "grade_id": "cell-227fe933ccc94d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The program should pass the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16f7f28859a9dca8147d1d2c32827316",
     "grade": true,
     "grade_id": "cell-b70iii2456f2ad27",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "avg = average_length(\"data/quixote.txt\")\n",
    "test(round(avg,5), 4.36684,'Try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1b6d43546d3e14913af54abddbab98d",
     "grade": false,
     "grade_id": "cell-062d11caf5156ppp",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **Option 2**. Using some built-in functions from Spark: you can think of a function available from Spark API that can simplify the implementation.\n",
    "\n",
    "                                                                                                       [10 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b213b01354be0e3f9c9b79591ab9baa3",
     "grade": false,
     "grade_id": "cell-016b9a4b1d83yyy8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def average_length(file_path):\n",
    "    # <FILL-IN WITH YOUR CODE>\n",
    "    \n",
    "average_length(\"data/quixote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0695b212d56267e50a2db36a8151644b",
     "grade": false,
     "grade_id": "cell-9db0ad40555a2b69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The program should pass the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1641b156f9e5c8607cc607214935612f",
     "grade": true,
     "grade_id": "cell-7f77mmma2bbef40b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "avg = average_length(\"data/quixote.txt\")\n",
    "test(round(avg,5), 4.36684,'Try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d567f5e9d2e0d2db48693eecaf0557e9",
     "grade": false,
     "grade_id": "cell-7111d2ea9f467ae9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4. Find a list of common friends between pairs of friends\n",
    "\n",
    "Obtain a list of common friends for each pair of friends. That is, for each two people that are friends (assuming friendship is bi-directional), you need to find the friends in common.\n",
    "\n",
    "You are asked to implement a function `common_friends(file_path)` that reads a file that contains a list of friends for each person. The function should output for each pair of friends, the list of common friends.\n",
    "\n",
    "**Input**: A file with the following format: Person -> List of friends. \n",
    "\n",
    "```\n",
    "Isaac -> Mikel John Lucy\n",
    "Mikel -> Isaac John Lucy Claudia\n",
    "John -> Isaac Mikel Lucy Claudia\n",
    "Lucy -> Isaac Mikel John Claudia\n",
    "Claudia -> Mikel John Lucy\n",
    "```\n",
    "\n",
    "**Output**: (pair of friends, list of common friends)\n",
    "```\n",
    "(Isaac, Mikel)    -> [John, Lucy]\n",
    "(Claudia, Mikel)  -> [John, Lucy]\n",
    "(John, Lucy)      -> [Claudia, Isaac, Mikel]\n",
    "(Isaac, John)     -> [Lucy, Mikel]\n",
    "(Isaac, Lucy)     -> [John, Mikel]\n",
    "(John, Mikel)     -> [Claudia, Isaac, Lucy]\n",
    "(Lucy, Mikel)     -> [Claudia, Isaac, John]\n",
    "(Claudia, John)   -> [Lucy, Mikel]\n",
    "(Claudia, Lucy)   -> [John, Mikel]\n",
    "\n",
    "```\n",
    "\n",
    "You could follow similar steps to the ones in the previous exercise:\n",
    "\n",
    "- Parse the input file to create an RDD of tuples like this: \n",
    "\n",
    "```\n",
    "[\n",
    " ('Isaac', ['Mikel', 'John', 'Lucy']),\n",
    " ('Mikel', ['Isaac', 'John', 'Lucy', 'Claudia']),\n",
    " ('John', ['Isaac', 'Mikel', 'Lucy', 'Claudia']),\n",
    " ('Lucy', ['Isaac', 'Mikel', 'John', 'Claudia']),\n",
    " ('Claudia', ['Mikel', 'John', 'Lucy'])\n",
    "]\n",
    "```\n",
    "\n",
    "- For each one of these, we would recommend a function to create a list of tuples that looks like this:\n",
    "\n",
    "```\n",
    "[\n",
    " (('Isaac', 'Mikel'), ['Mikel', 'John', 'Lucy']),\n",
    " (('Isaac', 'John'), ['Mikel', 'John', 'Lucy']),\n",
    " (('Isaac', 'Lucy'), ['Mikel', 'John', 'Lucy'])\n",
    "]\n",
    "```\n",
    "\n",
    "**Note**:  Make sure you sort the tuples that will be acting as keys. Lists cannot be used as keys in Spark because they are mutable. When you sort a tuple with `sorted`, you will get a list, which must be converted back to a tuple.\n",
    " \n",
    "- You will have to aggregate those results by key and perform the final intersection of list of friends.\n",
    "\n",
    "                                                                                                       [25 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f66057038cd9019ca79cb09fc8912f93",
     "grade": false,
     "grade_id": "cell-1f34f7d187fd5679",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Isaac', 'Mikel'), ['John', 'Lucy']),\n",
       " (('John', 'Lucy'), ['Claudia', 'Isaac', 'Mikel']),\n",
       " (('Claudia', 'Isaac'), ['John', 'Lucy', 'Mikel']),\n",
       " (('Claudia', 'Lucy'), ['John', 'Mikel']),\n",
       " (('John', 'Mikel'), ['Claudia', 'Isaac', 'Lucy']),\n",
       " (('Lucy', 'Mikel'), ['Claudia', 'Isaac', 'John']),\n",
       " (('Claudia', 'John'), ['Lucy', 'Mikel']),\n",
       " (('Isaac', 'Lucy'), ['John', 'Mikel']),\n",
       " (('Claudia', 'Mikel'), ['John', 'Lucy']),\n",
       " (('Isaac', 'John'), ['Lucy', 'Mikel'])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPerson(string):\n",
    "    return string[0:string.find('-') - 1]\n",
    "\n",
    "def getFriends(string):\n",
    "    friends = string[string.find('>') + 2::]\n",
    "    friendsList = friends.split(' ')\n",
    "    return friendsList\n",
    "\n",
    "def splitFriendList(keyList, value):\n",
    "    relationshipList = []\n",
    "    \n",
    "    for key in keyList:\n",
    "        relationshipList.append(key + \", \" + value)\n",
    "        \n",
    "    return relationshipList\n",
    "\n",
    "def getRelationshipComb(key, valueList):\n",
    "    relationshipCombList = []\n",
    "    \n",
    "    for i in range(len(valueList)):\n",
    "        j = i + 1\n",
    "        \n",
    "        while j < len(valueList):\n",
    "            relationshipCombList.append(valueList[i] + \" \" + valueList[j] + \", \" + key)\n",
    "            j += 1\n",
    "    \n",
    "    return relationshipCombList\n",
    "\n",
    "def getRelationshipCombTuple(string):\n",
    "    relationshipComb = string[0:string.find(',')]\n",
    "    relationshipCombList = relationshipComb.split(' ')\n",
    "    relationshipCombList.sort()\n",
    "    return tuple(relationshipCombList)\n",
    "    \n",
    "def common_friends(file_path):\n",
    "    # <FILL-IN WITH YOUR CODE>\n",
    "    lines = sc.textFile(file_path, 10)\n",
    "    mapFriendLists = lines.map(lambda line: (getFriends(line), getPerson(line)))\n",
    "    mapRelationshipList = mapFriendLists.flatMap(lambda x: splitFriendList(x[0], x[1]))\n",
    "    mapRelationships = mapRelationshipList.map(lambda relationship: (relationship[0:relationship.find(',')], \n",
    "                                                                    [relationship[relationship.find(' ') \n",
    "                                                                                 + 1::]]))\n",
    "    mapPersonFriendList = mapRelationships.reduceByKey(lambda list1, list2: list1 + list2)\n",
    "    mapRelationshipCombList = mapPersonFriendList.flatMap(lambda x: getRelationshipComb(x[0], x[1]))\n",
    "    mapRelationshipComb = mapRelationshipCombList.map(lambda string: (getRelationshipCombTuple(string),\n",
    "                                                                     [string[string.find(',') + 2::]]))\n",
    "    output = mapRelationshipComb.reduceByKey(lambda list1, list2: list1 + list2)\n",
    "    outputSortedValues = output.map(lambda x: (x[0], sorted(x[1])))\n",
    "    return outputSortedValues.collect()\n",
    "\n",
    "common_friends(\"data/friends.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbecac8a21455cd5f0963116853e51d4",
     "grade": false,
     "grade_id": "cell-cca79e0781rrr4bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The program should pass the following test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a97da27dabe340704c7dcc8200939ea",
     "grade": true,
     "grade_id": "cell-220e62dc94rr30e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. Try again!\n"
     ]
    }
   ],
   "source": [
    "test(sorted(map(lambda t: (t[0], sorted(t[1])), common_friends(\"data/friends.txt\"))), \n",
    "                  sorted(map(lambda t: (t[0], sorted(t[1])), [(('Isaac', 'Mikel'), ['John', 'Lucy']),\n",
    "                                                              (('Claudia', 'Mikel'), ['John', 'Lucy']),\n",
    "                                                              (('John', 'Lucy'), ['Claudia', 'Isaac', 'Mikel']),\n",
    "                                                              (('Isaac', 'John'), ['Lucy', 'Mikel']),\n",
    "                                                              (('Isaac', 'Lucy'), ['John', 'Mikel']),\n",
    "                                                              (('John', 'Mikel'), ['Claudia', 'Isaac', 'Lucy']),\n",
    "                                                              (('Lucy', 'Mikel'), ['Claudia', 'Isaac', 'John']),\n",
    "                                                              (('Claudia', 'John'), ['Lucy', 'Mikel']),\n",
    "                                                              (('Claudia', 'Lucy'), ['John', 'Mikel'])])), \n",
    "                  'Try again!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
